---
title: 'The Value of Algorithms'
date: 'Sep 2, 2021'
excerpt: "Why optimizing an ML algorithm's performance is not necessarily the same as optimizing the value that algorithm creates."
cover_image: '/images/posts/1.jpg'
cover_image_caption: 'Entity Resolution is a very common ML problem.'
author: 'Alex Berndt'
---

*Soon to be published ...*

<!-- A common theme in data science is a passion for algorithms, models and complicated mathematical models.

Although these are all great, I would propose that any data scientist or machine learning engineer should approach their role as a problem solver, which has data to help them do this.

**When you are a hammer, you see everything as a nail.**

As data scientists, we should approach problems without even considering the data as the starting point, and then slowly using more and more data as we need it (as an increase in performance is required).

Essentially, this article is the **start simple** version of the data science domain.

If you can solve the problem _without_ data, do so!  Why? Data is inherently noisy, messy and requires an entire infrastructure to be managed. If you achieve your end-goal without using data, then just don't use it. 

Just because you are a data scientist, doesn't mean you have to use data whenever you solve a problem.

Rather, see data as _one of many_ tools in your _toolbox_, and use the appropriate tools to solve the problem.


Always start with the simplest case:

if you can use just a simple transformation, and obtain acceptable results, without an machine-learning whatsoever, use that! Simple algorithms are inherently more robust, and should almost always be favored over more complicated approaches.

Of course, the assumption here being that your test data is sufficiently representative of your final use case. -->
